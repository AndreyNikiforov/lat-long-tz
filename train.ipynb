{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1734279641072
        },
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "Retrieving notices: done\n",
            "\n",
            "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
            "\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# adding kernel\n",
        "# https://medium.com/@lerouxpierre/how-to-add-kernels-to-your-jupyter-notebooks-within-azure-ml-studio-6495895c9d4a\n",
        "# fix \"kernel reset\" error\n",
        "# https://stackoverflow.com/questions/77902093/error-kernel-reset-in-azure-ml-compute-jupyterlab\n",
        "\n",
        "# %conda config --append channels anaconda\n",
        "# %conda config --add channels conda-forge\n",
        "# %conda config --add channels conda\n",
        "\n",
        "# to allow conda managing pypi packages\n",
        "%conda config --set pip_interop_enabled True\n",
        "\n",
        "# %conda update -n base conda\n",
        "# %conda install python=3.12 dask=2024.12.0 adlfs=2024.7.0 pytorch=2.5.1 scikit-learn=1.5.1 pyarrow=18.0.0 pandas=2.2.3 numpy=2.2.0\n",
        "\n",
        "%conda install scikit-learn=1.5.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1733724558668
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "add_anaconda_token: True\n",
            "add_pip_as_python_dependency: True\n",
            "aggressive_update_packages:\n",
            "  - ca-certificates\n",
            "  - certifi\n",
            "  - openssl\n",
            "allow_conda_downgrades: False\n",
            "allow_cycles: True\n",
            "allow_non_channel_urls: False\n",
            "allow_softlinks: False\n",
            "allowlist_channels: []\n",
            "always_copy: False\n",
            "always_softlink: False\n",
            "always_yes: None\n",
            "anaconda_anon_usage: True\n",
            "anaconda_upload: None\n",
            "auto_activate_base: True\n",
            "auto_stack: 0\n",
            "auto_update_conda: True\n",
            "bld_path: \n",
            "changeps1: True\n",
            "channel_alias: https://conda.anaconda.org\n",
            "channel_priority: flexible\n",
            "channel_settings: []\n",
            "channels:\n",
            "  - conda\n",
            "  - conda-forge\n",
            "  - defaults\n",
            "client_ssl_cert: None\n",
            "client_ssl_cert_key: None\n",
            "clobber: False\n",
            "conda_build: {}\n",
            "console: classic\n",
            "create_default_packages: []\n",
            "croot: /opt/conda/conda-bld\n",
            "custom_channels:\n",
            "  pkgs/main: https://repo.anaconda.com\n",
            "  pkgs/r: https://repo.anaconda.com\n",
            "  pkgs/pro: https://repo.anaconda.com\n",
            "custom_multichannels:\n",
            "  defaults: \n",
            "    - https://repo.anaconda.com/pkgs/main\n",
            "    - https://repo.anaconda.com/pkgs/r\n",
            "  local: \n",
            "debug: False\n",
            "default_channels:\n",
            "  - https://repo.anaconda.com/pkgs/main\n",
            "  - https://repo.anaconda.com/pkgs/r\n",
            "default_python: 3.12\n",
            "default_threads: None\n",
            "denylist_channels: []\n",
            "deps_modifier: not_set\n",
            "dev: False\n",
            "disallowed_packages: []\n",
            "download_only: False\n",
            "dry_run: False\n",
            "enable_private_envs: False\n",
            "env_prompt: ({default_env}) \n",
            "envs_dirs:\n",
            "  - /opt/conda/envs\n",
            "  - /home/vscode/.conda/envs\n",
            "envvars_force_uppercase: True\n",
            "error_upload_url: https://conda.io/conda-post/unexpected-error\n",
            "execute_threads: 1\n",
            "experimental: []\n",
            "extra_safety_checks: False\n",
            "fetch_threads: 5\n",
            "force: False\n",
            "force_32bit: False\n",
            "force_reinstall: False\n",
            "force_remove: False\n",
            "ignore_pinned: False\n",
            "json: False\n",
            "local_repodata_ttl: 1\n",
            "migrated_channel_aliases: []\n",
            "migrated_custom_channels: {}\n",
            "no_lock: False\n",
            "no_plugins: False\n",
            "non_admin_enabled: True\n",
            "notify_outdated_conda: True\n",
            "number_channel_notices: 5\n",
            "offline: False\n",
            "override_channels_enabled: True\n",
            "path_conflict: clobber\n",
            "pinned_packages: []\n",
            "pip_interop_enabled: True\n",
            "pkgs_dirs:\n",
            "  - /opt/conda/pkgs\n",
            "  - /home/vscode/.conda/pkgs\n",
            "proxy_servers: {}\n",
            "quiet: False\n",
            "register_envs: True\n",
            "remote_backoff_factor: 1\n",
            "remote_connect_timeout_secs: 9.15\n",
            "remote_max_retries: 3\n",
            "remote_read_timeout_secs: 60.0\n",
            "repodata_fns:\n",
            "  - current_repodata.json\n",
            "  - repodata.json\n",
            "repodata_threads: None\n",
            "repodata_use_zst: True\n",
            "report_errors: None\n",
            "restore_free_channel: False\n",
            "rollback_enabled: True\n",
            "root_prefix: /opt/conda\n",
            "safety_checks: warn\n",
            "sat_solver: pycosat\n",
            "separate_format_cache: False\n",
            "shortcuts: True\n",
            "shortcuts_only: []\n",
            "show_channel_urls: None\n",
            "signing_metadata_url_base: None\n",
            "solver: libmamba\n",
            "solver_ignore_timestamps: False\n",
            "ssl_verify: True\n",
            "subdir: linux-aarch64\n",
            "subdirs:\n",
            "  - linux-aarch64\n",
            "  - noarch\n",
            "target_prefix_override: \n",
            "trace: False\n",
            "track_features: []\n",
            "unsatisfiable_hints: True\n",
            "unsatisfiable_hints_check_depth: 2\n",
            "update_modifier: update_specs\n",
            "use_index_cache: False\n",
            "use_local: False\n",
            "use_only_tar_bz2: None\n",
            "verbosity: 0\n",
            "verify_threads: 1\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%conda config --show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1734279651432
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "# packages in environment at /opt/conda:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "_libgcc_mutex             0.1                        main  \n",
            "_openmp_mutex             5.1                      51_gnu  \n",
            "adal                      1.2.7              pyhd8ed1ab_0    conda-forge\n",
            "adlfs                     2024.7.0           pyhd8ed1ab_0    conda-forge\n",
            "aiohappyeyeballs          2.4.4              pyhd8ed1ab_1    conda-forge\n",
            "aiohttp                   3.11.9          py312hcc812fe_0    conda-forge\n",
            "aiosignal                 1.3.1              pyhd8ed1ab_1    conda-forge\n",
            "anaconda-anon-usage       0.4.4           py312h7d20cce_100  \n",
            "archspec                  0.2.3              pyhd3eb1b0_0  \n",
            "asttokens                 2.0.5              pyhd3eb1b0_0  \n",
            "attrs                     24.2.0             pyh71513ae_1    conda-forge\n",
            "aws-c-auth                0.8.0               hac900a4_10    conda-forge\n",
            "aws-c-cal                 0.8.0                h35473ba_2    conda-forge\n",
            "aws-c-common              0.10.3               h86ecc28_0    conda-forge\n",
            "aws-c-compression         0.3.0                h4c7db1d_2    conda-forge\n",
            "aws-c-event-stream        0.5.0                h9bacb8c_7    conda-forge\n",
            "aws-c-http                0.9.1                hf4e072c_2    conda-forge\n",
            "aws-c-io                  0.15.2               h10eb1bc_2    conda-forge\n",
            "aws-c-mqtt                0.11.0               h28a5e6a_8    conda-forge\n",
            "aws-c-s3                  0.7.2                h29aef15_0    conda-forge\n",
            "aws-c-sdkutils            0.2.1                h4c7db1d_1    conda-forge\n",
            "aws-checksums             0.2.2                h4c7db1d_1    conda-forge\n",
            "aws-crt-cpp               0.29.5               h6068a22_1    conda-forge\n",
            "aws-sdk-cpp               1.11.449             h775d804_3    conda-forge\n",
            "azure-core                1.32.0             pyhff2d567_0    conda-forge\n",
            "azure-core-cpp            1.14.0               h1887c18_0    conda-forge\n",
            "azure-datalake-store      0.0.51             pyh9f0ad1d_0    conda-forge\n",
            "azure-identity            1.17.1             pyhd8ed1ab_0    conda-forge\n",
            "azure-identity-cpp        1.10.0               h47b0b28_0    conda-forge\n",
            "azure-storage-blob        12.24.0            pyhff2d567_0    conda-forge\n",
            "azure-storage-blobs-cpp   12.13.0              h185ecfd_1    conda-forge\n",
            "azure-storage-common-cpp  12.8.0               h1b94036_1    conda-forge\n",
            "azure-storage-files-datalake-cpp 12.12.0              h37d6d07_1    conda-forge\n",
            "bokeh                     3.6.2              pyhd8ed1ab_1    conda-forge\n",
            "boltons                   23.0.0          py312hd43f75c_0  \n",
            "brotli-python             1.0.9           py312h419075a_8  \n",
            "bzip2                     1.0.8                h998d150_6  \n",
            "c-ares                    1.34.3               h86ecc28_1    conda-forge\n",
            "ca-certificates           2024.11.26           hd43f75c_0  \n",
            "certifi                   2024.8.30          pyhd8ed1ab_0    conda-forge\n",
            "cffi                      1.16.0          py312h998d150_1  \n",
            "charset-normalizer        3.3.2              pyhd3eb1b0_0  \n",
            "click                     8.1.7           unix_pyh707e725_1    conda-forge\n",
            "cloudpickle               3.1.0              pyhd8ed1ab_1    conda-forge\n",
            "comm                      0.2.1           py312hd43f75c_0  \n",
            "conda                     24.11.0         py312h996f985_0    conda-forge\n",
            "conda-content-trust       0.2.0           py312hd43f75c_1  \n",
            "conda-libmamba-solver     24.7.0             pyhd3eb1b0_0  \n",
            "conda-package-handling    2.3.0           py312hd43f75c_0  \n",
            "conda-package-streaming   0.10.0          py312hd43f75c_0  \n",
            "contourpy                 1.3.1           py312h451a7dd_0    conda-forge\n",
            "cryptography              43.0.1                   pypi_0    pypi\n",
            "cytoolz                   1.0.0           py312h52516f5_1    conda-forge\n",
            "dask                      2024.12.0          pyhd8ed1ab_1    conda-forge\n",
            "dask-core                 2024.12.0          pyhd8ed1ab_1    conda-forge\n",
            "dask-expr                 1.1.20             pyhd8ed1ab_0    conda-forge\n",
            "debugpy                   1.6.7           py312h419075a_0  \n",
            "decorator                 5.1.1              pyhd3eb1b0_0  \n",
            "distributed               2024.12.0          pyhd8ed1ab_1    conda-forge\n",
            "distro                    1.9.0           py312hd43f75c_0  \n",
            "executing                 0.8.3              pyhd3eb1b0_0  \n",
            "expat                     2.6.2                h419075a_0  \n",
            "filelock                  3.16.1             pyhd8ed1ab_1    conda-forge\n",
            "fmt                       9.1.0                hb8fdbf2_1  \n",
            "freetype                  2.12.1               hf0a5ef3_2    conda-forge\n",
            "frozendict                2.4.2           py312hd43f75c_0  \n",
            "frozenlist                1.5.0           py312hb2c0f52_0    conda-forge\n",
            "fsspec                    2024.10.0          pyhd8ed1ab_1    conda-forge\n",
            "gflags                    2.2.2             h5ad3122_1005    conda-forge\n",
            "glog                      0.7.1                h468a4a4_0    conda-forge\n",
            "gmp                       6.3.0                h0a1ffab_2    conda-forge\n",
            "gmpy2                     2.1.5           py312he9d48ea_3    conda-forge\n",
            "icu                       75.1                 hf9b3779_0    conda-forge\n",
            "idna                      3.7             py312hd43f75c_0  \n",
            "importlib-metadata        8.5.0              pyha770c72_1    conda-forge\n",
            "ipykernel                 6.29.5          py312hd43f75c_0  \n",
            "ipython                   8.27.0          py312hd43f75c_0  \n",
            "isodate                   0.7.2              pyhd8ed1ab_1    conda-forge\n",
            "jedi                      0.19.1          py312hd43f75c_0  \n",
            "jinja2                    3.1.4              pyhd8ed1ab_1    conda-forge\n",
            "joblib                    1.4.2              pyhd8ed1ab_1    conda-forge\n",
            "jsonpatch                 1.33            py312hd43f75c_1  \n",
            "jsonpointer               2.1                pyhd3eb1b0_0  \n",
            "jupyter_client            8.6.0           py312hd43f75c_0  \n",
            "jupyter_core              5.7.2           py312hd43f75c_0  \n",
            "keyutils                  1.6.1                h4e544f5_0    conda-forge\n",
            "krb5                      1.21.3               h50a48e9_0    conda-forge\n",
            "lcms2                     2.16                 h922389a_0    conda-forge\n",
            "ld_impl_linux-aarch64     2.38                 h8131f2d_1  \n",
            "lerc                      4.0.0                h4de3ea5_0    conda-forge\n",
            "libabseil                 20240722.0      cxx17_h5ad3122_1    conda-forge\n",
            "libarchive                3.7.7                h2f0f0fe_0    conda-forge\n",
            "libarrow                  18.0.0           h3d75c4c_9_cpu    conda-forge\n",
            "libarrow-acero            18.0.0           h5ad3122_9_cpu    conda-forge\n",
            "libarrow-dataset          18.0.0           h5ad3122_9_cpu    conda-forge\n",
            "libarrow-substrait        18.0.0           h14ec2bd_9_cpu    conda-forge\n",
            "libblas                   3.9.0           25_linuxaarch64_openblas    conda-forge\n",
            "libbrotlicommon           1.1.0                h86ecc28_2    conda-forge\n",
            "libbrotlidec              1.1.0                h86ecc28_2    conda-forge\n",
            "libbrotlienc              1.1.0                h86ecc28_2    conda-forge\n",
            "libcblas                  3.9.0           25_linuxaarch64_openblas    conda-forge\n",
            "libcrc32c                 1.1.2                h01db608_0    conda-forge\n",
            "libcurl                   8.10.1               h3ec0cbf_0    conda-forge\n",
            "libdeflate                1.22                 h86ecc28_0    conda-forge\n",
            "libedit                   3.1.20230828         h998d150_0  \n",
            "libev                     4.33                 hfd63f10_1  \n",
            "libevent                  2.1.12               h4ba1bb4_1    conda-forge\n",
            "libexpat                  2.6.2                h2f0025b_0    conda-forge\n",
            "libffi                    3.4.4                h419075a_1  \n",
            "libgcc                    14.2.0               he277a41_1    conda-forge\n",
            "libgcc-ng                 14.2.0               he9431aa_1    conda-forge\n",
            "libgfortran               14.2.0               he9431aa_1    conda-forge\n",
            "libgfortran5              14.2.0               hb6113d0_1    conda-forge\n",
            "libgomp                   14.2.0               he277a41_1    conda-forge\n",
            "libgoogle-cloud           2.31.0               h3888205_0    conda-forge\n",
            "libgoogle-cloud-storage   2.31.0               hb9b2b65_0    conda-forge\n",
            "libgrpc                   1.67.1               h36c5df4_0    conda-forge\n",
            "libiconv                  1.17                 h31becfc_2    conda-forge\n",
            "libjpeg-turbo             3.0.0                h31becfc_1    conda-forge\n",
            "liblapack                 3.9.0           25_linuxaarch64_openblas    conda-forge\n",
            "liblzma                   5.6.3                h86ecc28_1    conda-forge\n",
            "libmamba                  1.5.11               h0a4e7f9_0  \n",
            "libmambapy                1.5.11          py312h78dbd8a_0  \n",
            "libnghttp2                1.64.0               hc8609a4_0    conda-forge\n",
            "libnsl                    2.0.1                h31becfc_0    conda-forge\n",
            "libopenblas               0.3.28          pthreads_h9d3fd7e_1    conda-forge\n",
            "libparquet                18.0.0           h23a96eb_9_cpu    conda-forge\n",
            "libpng                    1.6.44               hc4a20ef_0    conda-forge\n",
            "libprotobuf               5.28.2               h029595c_0    conda-forge\n",
            "libre2-11                 2024.07.02           h18dbdb1_1    conda-forge\n",
            "libsodium                 1.0.18               hfd63f10_0  \n",
            "libsolv                   0.7.30               h62756fc_0    conda-forge\n",
            "libsqlite                 3.45.2               h194ca79_0    conda-forge\n",
            "libssh2                   1.11.1               ha41c0db_0    conda-forge\n",
            "libstdcxx                 14.2.0               h3f4de04_1    conda-forge\n",
            "libstdcxx-ng              14.2.0               hf1166c9_1    conda-forge\n",
            "libthrift                 0.21.0               h154c74f_0    conda-forge\n",
            "libtiff                   4.7.0                hca96517_2    conda-forge\n",
            "libtorch                  2.5.1           cpu_generic_hc93d7ea_6    conda-forge\n",
            "libutf8proc               2.8.0                h812390e_1    conda-forge\n",
            "libuuid                   2.38.1               hb4cce97_0    conda-forge\n",
            "libuv                     1.49.2               h86ecc28_0    conda-forge\n",
            "libwebp-base              1.4.0                h31becfc_0    conda-forge\n",
            "libxcb                    1.17.0               h262b8f6_0    conda-forge\n",
            "libxcrypt                 4.4.36               h31becfc_1    conda-forge\n",
            "libxml2                   2.13.5               h2e0c361_1    conda-forge\n",
            "libzlib                   1.3.1                h86ecc28_2    conda-forge\n",
            "locket                    1.0.0              pyhd8ed1ab_0    conda-forge\n",
            "lz4                       4.3.3           py312h8c5c2bf_1    conda-forge\n",
            "lz4-c                     1.9.4                h419075a_1  \n",
            "lzo                       2.10              h31becfc_1001    conda-forge\n",
            "markupsafe                3.0.2           py312h74ce7d3_1    conda-forge\n",
            "matplotlib-inline         0.1.6           py312hd43f75c_0  \n",
            "menuinst                  2.1.2           py312hd43f75c_0  \n",
            "mpc                       1.3.1                h783934e_1    conda-forge\n",
            "mpfr                      4.2.1                h2305555_3    conda-forge\n",
            "mpmath                    1.3.0              pyhd8ed1ab_1    conda-forge\n",
            "msal                      1.31.0             pyhd8ed1ab_0    conda-forge\n",
            "msal_extensions           1.0.0              pyhd8ed1ab_0    conda-forge\n",
            "msgpack-python            1.1.0           py312h451a7dd_0    conda-forge\n",
            "multidict                 6.1.0           py312hcc812fe_1    conda-forge\n",
            "ncurses                   6.4                  h419075a_0  \n",
            "nest-asyncio              1.6.0           py312hd43f75c_0  \n",
            "networkx                  3.4.2              pyh267e887_2    conda-forge\n",
            "nomkl                     1.0                  h5ca1d4c_0    conda-forge\n",
            "numpy                     2.2.0           py312h4dce2f2_0    conda-forge\n",
            "openjpeg                  2.5.2                h0d9d63b_0    conda-forge\n",
            "openssl                   3.4.0                h86ecc28_0    conda-forge\n",
            "orc                       2.0.3                h90de224_0    conda-forge\n",
            "packaging                 24.1            py312hd43f75c_0  \n",
            "pandas                    2.2.3           py312ha2895bd_1    conda-forge\n",
            "parso                     0.8.3              pyhd3eb1b0_0  \n",
            "partd                     1.4.2              pyhd8ed1ab_0    conda-forge\n",
            "pcre2                     10.44                h070dd5b_2    conda-forge\n",
            "pexpect                   4.8.0              pyhd3eb1b0_3  \n",
            "pillow                    11.0.0          py312h5ab5af3_0    conda-forge\n",
            "pip                       24.2            py312hd43f75c_0  \n",
            "platformdirs              3.10.0          py312hd43f75c_0  \n",
            "pluggy                    1.0.0           py312hd43f75c_1  \n",
            "portalocker               2.10.1          py312h8025657_1    conda-forge\n",
            "prompt-toolkit            3.0.43          py312hd43f75c_0  \n",
            "prompt_toolkit            3.0.43               hd3eb1b0_0  \n",
            "propcache                 0.2.1           py312hb2c0f52_0    conda-forge\n",
            "psutil                    5.9.0           py312h998d150_0  \n",
            "pthread-stubs             0.4               h86ecc28_1002    conda-forge\n",
            "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
            "pure_eval                 0.2.2              pyhd3eb1b0_0  \n",
            "pyarrow                   18.0.0          py312h8025657_2    conda-forge\n",
            "pyarrow-core              18.0.0          py312h66f7834_2_cpu    conda-forge\n",
            "pybind11-abi              5                    hd3eb1b0_0  \n",
            "pycosat                   0.6.6           py312h998d150_1  \n",
            "pycparser                 2.21               pyhd3eb1b0_0  \n",
            "pygments                  2.15.1          py312hd43f75c_1  \n",
            "pyjwt                     2.10.1             pyhd8ed1ab_0    conda-forge\n",
            "pysocks                   1.7.1           py312hd43f75c_0  \n",
            "python                    3.12.2          h43d1f9e_0_cpython    conda-forge\n",
            "python-dateutil           2.9.0post0      py312hd43f75c_2  \n",
            "python-tzdata             2024.2             pyhd8ed1ab_1    conda-forge\n",
            "python_abi                3.12                    5_cp312    conda-forge\n",
            "pytorch                   2.5.1           cpu_generic_py312he02225e_6    conda-forge\n",
            "pytz                      2024.1             pyhd8ed1ab_0    conda-forge\n",
            "pyyaml                    6.0.2           py312hb2c0f52_1    conda-forge\n",
            "pyzmq                     25.1.2          py312h419075a_0  \n",
            "re2                       2024.07.02           h2d3a13d_1    conda-forge\n",
            "readline                  8.2                  h998d150_0  \n",
            "reproc                    14.2.4               h419075a_2  \n",
            "reproc-cpp                14.2.4               h419075a_2  \n",
            "requests                  2.32.3          py312hd43f75c_0  \n",
            "ruamel.yaml               0.17.21         py312h998d150_0  \n",
            "s2n                       1.5.9                h636ded1_0    conda-forge\n",
            "scikit-learn              1.5.1           py312h2605d20_1    conda-forge\n",
            "scipy                     1.14.1          py312hcbff3fa_2    conda-forge\n",
            "setuptools                72.1.0          py312hd43f75c_0  \n",
            "six                       1.16.0             pyhd3eb1b0_1  \n",
            "sleef                     3.7                  h8fb0607_2    conda-forge\n",
            "snappy                    1.2.1                hd4fb6f5_1    conda-forge\n",
            "sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge\n",
            "sqlite                    3.45.2               h3b3482f_0    conda-forge\n",
            "stack_data                0.2.0              pyhd3eb1b0_0  \n",
            "sympy                     1.13.3          pypyh2585a3b_103    conda-forge\n",
            "tblib                     3.0.0              pyhd8ed1ab_0    conda-forge\n",
            "threadpoolctl             3.5.0              pyhc1e730c_0    conda-forge\n",
            "tk                        8.6.13               h194ca79_0    conda-forge\n",
            "toolz                     1.0.0              pyhd8ed1ab_1    conda-forge\n",
            "tornado                   6.4.1           py312h998d150_0  \n",
            "tqdm                      4.66.4          py312h42ac6d5_0  \n",
            "traitlets                 5.14.3          py312hd43f75c_0  \n",
            "truststore                0.8.0           py312hd43f75c_0  \n",
            "typing-extensions         4.12.2               hd8ed1ab_1    conda-forge\n",
            "typing_extensions         4.12.2             pyha770c72_1    conda-forge\n",
            "tzdata                    2024a                h04d1e81_0  \n",
            "urllib3                   2.2.2           py312hd43f75c_0  \n",
            "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
            "wheel                     0.43.0          py312hd43f75c_0  \n",
            "xorg-libxau               1.0.11               h86ecc28_1    conda-forge\n",
            "xorg-libxdmcp             1.1.5                h57736b2_0    conda-forge\n",
            "xyzservices               2024.9.0           pyhd8ed1ab_1    conda-forge\n",
            "xz                        5.4.6                h998d150_1  \n",
            "yaml                      0.2.5                hf897c2e_2    conda-forge\n",
            "yaml-cpp                  0.8.0                h419075a_1  \n",
            "yarl                      1.18.3          py312hb2c0f52_0    conda-forge\n",
            "zeromq                    4.3.5                h419075a_0  \n",
            "zict                      3.0.0              pyhd8ed1ab_1    conda-forge\n",
            "zipp                      3.21.0             pyhd8ed1ab_1    conda-forge\n",
            "zlib                      1.3.1                h86ecc28_2    conda-forge\n",
            "zstandard                 0.23.0          py312hb698573_1    conda-forge\n",
            "zstd                      1.5.6                h02f22dd_0    conda-forge\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%conda list\n",
        "# %conda --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1734279654797
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import dask.dataframe as dd\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1734279966455
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1734279672300
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lng</th>\n",
              "      <th>lat</th>\n",
              "      <th>tz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-180.0</td>\n",
              "      <td>-90.0</td>\n",
              "      <td>Antarctica/McMurdo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-180.0</td>\n",
              "      <td>-89.0</td>\n",
              "      <td>Antarctica/McMurdo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-180.0</td>\n",
              "      <td>-88.0</td>\n",
              "      <td>Antarctica/McMurdo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-180.0</td>\n",
              "      <td>-87.0</td>\n",
              "      <td>Antarctica/McMurdo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-180.0</td>\n",
              "      <td>-86.0</td>\n",
              "      <td>Antarctica/McMurdo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lng   lat                  tz\n",
              "0 -180.0 -90.0  Antarctica/McMurdo\n",
              "1 -180.0 -89.0  Antarctica/McMurdo\n",
              "2 -180.0 -88.0  Antarctica/McMurdo\n",
              "3 -180.0 -87.0  Antarctica/McMurdo\n",
              "4 -180.0 -86.0  Antarctica/McMurdo"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "storage_options = {\n",
        "    \"account_name\": \"lnglattzw21586036186\",\n",
        "    \"account_key\" : \"REMOVED\",\n",
        "}\n",
        "\n",
        "df = pd.read_parquet(\n",
        "    [\"data2/lng-lat-tz/data0_0.parquet\",\n",
        "    \"data2/lng-lat-tz/data1_0.parquet\"],\n",
        "    # \"az://lng-lat-tz/data1*.parquet\",\n",
        "    # aggregate_files     = True,\n",
        "    # split_row_groups    = 'adaptive',\n",
        "    # storage_options     = storage_options,\n",
        "    # dtype={'lng': 'float', 'lat': 'float', 'tz': 'string'}\n",
        "    # use_nullable_dtypes = True,\n",
        ")\n",
        "\n",
        "# test\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1734279667377
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# test azure with dask or pandas\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "# ddf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1734284550967
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, out_neurons):\n",
        "        super().__init__()\n",
        "        power_l1 = 9\n",
        "        power_l2 = 9\n",
        "        power_l3 = 9\n",
        "        power_l4 = 9\n",
        "        power_l5 = 9\n",
        "        power_l6 = 9\n",
        "        power_l7 = 9\n",
        "        power_l8 = 9\n",
        "        power_l9 = 9\n",
        "        power_l10 = 9\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2, 2 ** power_l1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2 ** power_l1, 2 ** power_l2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2 ** power_l2, 2 ** power_l3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2 ** power_l3, 2 ** power_l4),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l4, 2 ** power_l5),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l5, 2 ** power_l6),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l6, 2 ** power_l7),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l7, 2 ** power_l8),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l8, 2 ** power_l9),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(2 ** power_l9, 2 ** power_l10),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(2 ** power_l10, out_neurons),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1734284553277
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def train_loop(batch_size, dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1734232610577
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# memorize \n",
        "# df = df.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1734284555856
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "# validate device\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1734284559213
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "y = df.drop(['lng', 'lat'], axis=1)\n",
        "X = df.drop(['tz'], axis=1)\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "# X_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "l_t = LabelEncoder()\n",
        "y_label_encoding = y.apply(lambda x : l_t.fit_transform(x))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_label_encoding, test_size = 0.2, shuffle= True)\n",
        "\n",
        "X_train = torch.FloatTensor(X_train.values).to(device)\n",
        "X_test = torch.FloatTensor(X_test.values).to(device)\n",
        "y_train = torch.flatten(torch.LongTensor(y_train.values)).to(device)\n",
        "y_test = torch.flatten(torch.LongTensor(y_test.values)).to(device)\n",
        "\n",
        "training_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1734284651488
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 6.744044  [  256/5227280]\n",
            "loss: 2.671168  [25856/5227280]\n",
            "loss: 2.513271  [51456/5227280]\n",
            "loss: 2.349571  [77056/5227280]\n",
            "loss: 2.509453  [102656/5227280]\n",
            "loss: 2.232852  [128256/5227280]\n",
            "loss: 2.165662  [153856/5227280]\n",
            "loss: 1.957676  [179456/5227280]\n",
            "loss: 1.704183  [205056/5227280]\n",
            "loss: 1.462879  [230656/5227280]\n",
            "loss: 1.666758  [256256/5227280]\n",
            "loss: 1.331662  [281856/5227280]\n",
            "loss: 1.214738  [307456/5227280]\n",
            "loss: 1.168369  [333056/5227280]\n",
            "loss: 1.233789  [358656/5227280]\n",
            "loss: 1.152494  [384256/5227280]\n",
            "loss: 0.984424  [409856/5227280]\n",
            "loss: 1.087095  [435456/5227280]\n",
            "loss: 0.885370  [461056/5227280]\n",
            "loss: 0.923831  [486656/5227280]\n",
            "loss: 0.913713  [512256/5227280]\n",
            "loss: 0.902058  [537856/5227280]\n",
            "loss: 0.869650  [563456/5227280]\n",
            "loss: 0.856224  [589056/5227280]\n",
            "loss: 0.850352  [614656/5227280]\n",
            "loss: 0.810772  [640256/5227280]\n",
            "loss: 0.759715  [665856/5227280]\n",
            "loss: 0.734086  [691456/5227280]\n",
            "loss: 0.757973  [717056/5227280]\n",
            "loss: 0.742336  [742656/5227280]\n",
            "loss: 0.712290  [768256/5227280]\n",
            "loss: 0.962022  [793856/5227280]\n",
            "loss: 0.836508  [819456/5227280]\n",
            "loss: 0.743820  [845056/5227280]\n",
            "loss: 0.824496  [870656/5227280]\n",
            "loss: 0.919519  [896256/5227280]\n",
            "loss: 0.761853  [921856/5227280]\n",
            "loss: 0.536354  [947456/5227280]\n",
            "loss: 0.802518  [973056/5227280]\n",
            "loss: 0.637921  [998656/5227280]\n",
            "loss: 0.652341  [1024256/5227280]\n",
            "loss: 0.502907  [1049856/5227280]\n",
            "loss: 0.974931  [1075456/5227280]\n",
            "loss: 0.637064  [1101056/5227280]\n",
            "loss: 0.641725  [1126656/5227280]\n",
            "loss: 0.575492  [1152256/5227280]\n",
            "loss: 0.693867  [1177856/5227280]\n",
            "loss: 0.650047  [1203456/5227280]\n",
            "loss: 0.647520  [1229056/5227280]\n",
            "loss: 0.580510  [1254656/5227280]\n",
            "loss: 0.628016  [1280256/5227280]\n",
            "loss: 0.599375  [1305856/5227280]\n",
            "loss: 0.640597  [1331456/5227280]\n",
            "loss: 0.539032  [1357056/5227280]\n",
            "loss: 0.505368  [1382656/5227280]\n",
            "loss: 0.449207  [1408256/5227280]\n",
            "loss: 0.573957  [1433856/5227280]\n",
            "loss: 0.545591  [1459456/5227280]\n",
            "loss: 0.630006  [1485056/5227280]\n",
            "loss: 0.558023  [1510656/5227280]\n",
            "loss: 0.553929  [1536256/5227280]\n",
            "loss: 0.561761  [1561856/5227280]\n",
            "loss: 0.773886  [1587456/5227280]\n",
            "loss: 0.533490  [1613056/5227280]\n",
            "loss: 0.462790  [1638656/5227280]\n",
            "loss: 0.663215  [1664256/5227280]\n",
            "loss: 0.509523  [1689856/5227280]\n",
            "loss: 0.559601  [1715456/5227280]\n",
            "loss: 0.566278  [1741056/5227280]\n",
            "loss: 0.608832  [1766656/5227280]\n",
            "loss: 0.621962  [1792256/5227280]\n",
            "loss: 0.639270  [1817856/5227280]\n",
            "loss: 0.513993  [1843456/5227280]\n",
            "loss: 0.515706  [1869056/5227280]\n",
            "loss: 0.573501  [1894656/5227280]\n",
            "loss: 0.567839  [1920256/5227280]\n",
            "loss: 0.514386  [1945856/5227280]\n",
            "loss: 0.481180  [1971456/5227280]\n",
            "loss: 0.511543  [1997056/5227280]\n",
            "loss: 0.517404  [2022656/5227280]\n",
            "loss: 0.421595  [2048256/5227280]\n",
            "loss: 0.435254  [2073856/5227280]\n",
            "loss: 0.564240  [2099456/5227280]\n",
            "loss: 0.632875  [2125056/5227280]\n",
            "loss: 0.644157  [2150656/5227280]\n",
            "loss: 0.414224  [2176256/5227280]\n",
            "loss: 0.409116  [2201856/5227280]\n",
            "loss: 0.502346  [2227456/5227280]\n",
            "loss: 0.454463  [2253056/5227280]\n",
            "loss: 0.585224  [2278656/5227280]\n",
            "loss: 0.697805  [2304256/5227280]\n",
            "loss: 0.584829  [2329856/5227280]\n",
            "loss: 0.375525  [2355456/5227280]\n",
            "loss: 0.571877  [2381056/5227280]\n",
            "loss: 0.440470  [2406656/5227280]\n",
            "loss: 0.602459  [2432256/5227280]\n",
            "loss: 0.565965  [2457856/5227280]\n",
            "loss: 0.552988  [2483456/5227280]\n",
            "loss: 0.467651  [2509056/5227280]\n",
            "loss: 0.658418  [2534656/5227280]\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-3 # 4\n",
        "batch_size = 32 * 8 # 32\n",
        "epochs = 1 # 100\n",
        "class_count = df['tz'].value_counts().count()\n",
        "model = NeuralNetwork(class_count).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(batch_size, train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "l2-2-r-data1-cpu(ef-box), batch=64, lr=0.001/Adam, epochs=1:\n",
        "- loading: ?\n",
        "- Accuracy: 32.7%, Avg loss: 2.712187\n",
        "- runtime: ?\n",
        "\n",
        "l2-2-r-data1-gpu, batch=64, lr=0.001/Adam, epochs=1:\n",
        "- loading: ?\n",
        "- Accuracy: 31.7%, Avg loss: 2.649778\n",
        "- runtime: 2:41\n",
        "\n",
        "l2-2-r-data2-gpu, batch=64, lr=0.001/Adam, epochs=1:\n",
        "- loading: 2:50\n",
        "- Accuracy: none\n",
        "- runtime: canceled after 1hr, est 4hrs \n",
        "- cpu: 100%\n",
        "- ram: 32%\n",
        "\n",
        "l2-2-r-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 30.7%, Avg loss: 2.920631\n",
        "- runtime: 1:18\n",
        "- cpu: 100%\n",
        "- ram: 15%\n",
        "\n",
        "l2-1K-r-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: NA\n",
        "- Accuracy: 79.1%, Avg loss: 0.598570\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 15%\n",
        "\n",
        "l2-1M-r-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- loss: 10\n",
        "- runtime: canceled after 8min\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-128-r-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 69.8%, Avg loss: 0.894220\n",
        "- runtime: 1:27\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-4K-r-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 78.8%, Avg loss: 0.582083\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 82.4%, Avg loss: 0.473214\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=10:\n",
        "- loading: 1sec\n",
        "- Accuracy: 89.0%, Avg loss: 0.293857\n",
        "- runtime: 14:38\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x8, lr=0.1/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 3.6%, Avg loss: 4.470265\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x8, lr=0.0001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 74.3%, Avg loss: 0.783508\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 70.3%, Avg loss: 0.942639\n",
        "- runtime: 5:02\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x16, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 79.8%, Avg loss: 0.530371\n",
        "- runtime: 1:05\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x4, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 78.7%, Avg loss: 0.557121\n",
        "- runtime: 1:50\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x3-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 78.1%, Avg loss: 0.532118\n",
        "- runtime: 1:30\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x2-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1 (reproduce prev result):\n",
        "- loading: 1sec\n",
        "- Accuracy: 81.9%, Avg loss: 0.494453\n",
        "- runtime: 1:26\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x5-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 84.7%, Avg loss: 0.388047\n",
        "- runtime: 1:42\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x10-data1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 80.7%, Avg loss: 0.532438\n",
        "- runtime: 2:04\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x5-data2-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 2:59\n",
        "- Accuracy: 95.2%, Avg loss: 0.118907\n",
        "- runtime: 2:48:00\n",
        "- cpu: 100%\n",
        "- ram: 32%\n",
        "\n",
        "l2-(512-r)x10-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 81.3%, Avg loss: 0.457877\n",
        "- runtime: 2:08\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x10-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=1, normalized:\n",
        "- loading: 1sec\n",
        "- Accuracy: 78.9%, Avg loss: 0.629528\n",
        "- runtime: 2:06\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(4K-r)x10-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=5, normalized:\n",
        "- loading: 1sec\n",
        "- Accuracy: 88.6%, Avg loss: 0.299482\n",
        "- runtime: 58:00\n",
        "- cpu: 100%\n",
        "- ram: 2%\n",
        "\n",
        "l2-(512-r)x7-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 84.5%, Avg loss: 0.385082\n",
        "- runtime: 1:43\n",
        "- cpu: 100%\n",
        "- ram: 1%\n",
        "\n",
        "l2-(512-r)x6-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 81.3%, Avg loss: 0.474233\n",
        "- runtime: 1:38\n",
        "- cpu: 100%\n",
        "- ram: 2%\n",
        "\n",
        "l2-(512-r)x4-data0+1-gpu, batch=32x8, lr=0.001/Adam, epochs=1:\n",
        "- loading: 1sec\n",
        "- Accuracy: 77.6%, Avg loss: 0.563156\n",
        "- runtime: 1:29\n",
        "- cpu: 100%\n",
        "- ram: 1%\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
