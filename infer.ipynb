{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1734287353582
        }
      },
      "outputs": [],
      "source": [
        "%conda config --set pip_interop_enabled True\n",
        "\n",
        "# %conda update -n base conda\n",
        "# %conda install python=3.12 dask=2024.12.0 adlfs=2024.7.0 pytorch=2.5.1 scikit-learn=1.5.1 pyarrow=18.0.0 pandas=2.2.3 numpy=2.2.0\n",
        "\n",
        "# %conda install \n",
        "%pip install onnxruntime==1.20.1\n",
        "# onnx=1.17.0 \n",
        "# %pip install onnxscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1734287491393
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import onnx\n",
        "# onnx_model = onnx.load(\"model_l5_d0_e1.onnx\")\n",
        "# onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# pip install onnxruntime\n",
        "# https://pytorch.org/tutorials/beginner/onnx/export_simple_model_to_onnx_tutorial.html\n",
        "\n",
        "# import onnxruntime\n",
        "# import torch\n",
        "\n",
        "lng=116.3883\n",
        "lat=39.9289\n",
        "# input = torch.FloatTensor([lng, lat])\n",
        "\n",
        "# onnx_input = onnx_model.adapt_torch_inputs_to_onnx(input)\n",
        "# print(f\"Input length: {len(onnx_input)}\")\n",
        "# print(f\"Sample input: {onnx_input}\")\n",
        "\n",
        "# ort_session = onnxruntime.InferenceSession(\"./model.onnx\", providers=['CPUExecutionProvider'])\n",
        "\n",
        "# def to_numpy(tensor):\n",
        "#     return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
        "\n",
        "# onnxruntime_outputs = ort_session.run(None, onnxruntime_input)\n",
        "\n",
        "# https://onnxruntime.ai/docs/get-started/with-python.html\n",
        "import onnxruntime as ort\n",
        "# import numpy as np\n",
        "# ort_sess = ort.InferenceSession('model_l5_d0_e1.onnx')\n",
        "# outputs = ort_sess.run(None, {'lng-lat': [[lng, lat]]})\n",
        "# print(outputs[0][0].argmax(0))\n",
        "\n",
        "ort_sess = ort.InferenceSession('model-l2-8-32-32-d01-e10.onnx')\n",
        "outputs = ort_sess.run(None, {'lng-lat': [[lng, lat]]})\n",
        "\n",
        "# Print Result\n",
        "print(outputs)\n",
        "print(outputs[0][0][0])\n",
        "# predicted, actual = classes[outputs[0][0].argmax(0)], classes[y]\n",
        "# print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
